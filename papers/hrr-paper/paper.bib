Automatically generated by Mendeley Desktop 1.16.3
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Kleyko:2016:HolographicGraphNeuron,
abstract = {This article proposes the use of Vector Symbolic Architectures for implementing Hierarchical Graph Neuron, an architecture for memorizing patterns of generic sensor stimuli. The adoption of a Vector Symbolic representation ensures a one-layered design for the approach, while maintaining the previously reported properties and performance characteristics of Hierarchical Graph Neuron, and also improving the noise resistance of the architecture. The proposed architecture enables a linear (with respect to the number of stored entries) time search for an arbitrary sub-pattern.},
archivePrefix = {arXiv},
arxivId = {1501.03784},
author = {Kleyko, Denis and Osipov, Evgeny and Senior, Alexander and Khan, Asad I. and Sekercioglu, Yasar Ahmet},
doi = {10.1109/TNNLS.2016.2535338},
eprint = {1501.03784},
file = {:home/ksiks/temp/1501.03784v1.pdf:pdf},
issn = {21622388},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
pages = {1--9},
title = {{Holographic Graph Neuron: A Bioinspired Architecture for Pattern Processing}},
year = {2016}
}
@article{Patyk-Lonska:2011:DistributedRepresentationsBased,
abstract = {Authors revise the concept of a distributed representation of data as well as two previously developed mod- els: Holographic Reduced Representation (HRR) and Binary Spatter Codes (BSC). A Geometric Analogue (GAc — "c" stands for continuous as opposed to its discrete version) of HRR is introduced – it employs role-filler binding based on geometric products. Atomic objects are real-valued vectors in n-dimensional Euclidean space while complex data structures belong to a hierarchy of multivectors. The paper reports on a test aimed at comparison of GAc with HRR and BSC. The test is analogous to the one proposed by Tony Plate in the mid 90s. We repeat Plate's test on GAc and compare the results with the original HRR and BSC — we concentrate on comparison of recognition percentage for the three models for comparable data size, rather than on the time taken to achieve high percentage. Results show that the best models for storing and recognizing multiple similar structures are GAc and BSC with recognition percentage highly above 90. The paper ends with remarks on perspective applications of geometric algebra to quantum algorithms.},
author = {Patyk-L{\'{o}}nska, Agnieszka and Czachor, Marek and Aerts, Diederik},
file = {:home/ksiks/temp/10.1.1.298.6032.pdf:pdf},
issn = {03505596},
journal = {Informatica (Ljubljana)},
keywords = {BSC,Distributed representation of data,Geometric algebra,HRR,Scaling},
number = {4},
pages = {407--417},
title = {{Distributed representations based on geometric Algebra: The continuous model}},
volume = {35},
year = {2011}
}
@article{Levy:2008:VectorSymbolicArchitectures,
abstract = {We provide an overviewofVector Symbolic Architectures (VSA), a class of structured associative memory models that offers a number of desirable features for artificial general intelligence. By directly encoding structure using familiar, computationally efficient algorithms, VSA bypasses many of the problems that have consumed unnecessary effort and attention in previous connectionist work. Example applications from opposite ends of the AI spectrum – visual map-seeking circuits and structured analogy processing – attest to the generality and power of the VSA approach in building new solutions for AI.},
author = {Levy, Simon D and Gayler, Ross W.},
file = {:home/ksiks/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Levy, Gayler - Unknown - Vector Symbolic Architectures A New Building Material for Artificial General Intelligence 1.pdf:pdf},
isbn = {978-1-58603-833-5},
issn = {09226389},
journal = {Proceedings of the First Conference on Artificial General Intelligence (AGI-08)},
keywords = {associative memory,binary spatter codes,connectionism,distributed representations,holographic reduced representation,vector symbolic architectures},
pages = {414--418},
pmid = {1000185213},
title = {{Vector Symbolic Architectures: A New Building Material for Artificial General Intelligence}},
url = {www.cs.wlu.edu/{~}levy/pubs/agi{\_}2008{\_}levy{\_}gayler.pdf$\backslash$nhttp://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.108.6978$\backslash$nhttp://sites.google.com/site/rgayler/agi{\_}2008{\_}levy{\_}gayler.pdf?attredirects=0},
year = {2008}
}
@book{Kleyko:2016:PatternRecognitionVector,
abstract = {Pattern recognition is an area constantly enlarging its theoretical and practical horizons. Applications of pattern recognition and machine learning can be found in many areas of the present day world including health-care, robotics, manufacturing, economics, automation, transportation, etc. Despite some success in many domains pattern recognition algorithms are still far from being close to their biological vis-a-vis – human brain. New possibilities in the area of pattern recognition may be achieved by application of biologically inspired approaches. This thesis presents the usage of a bio-inspired method of representing concepts and their meaning – Vector Symbolic Architectures – in the context of pattern recognition with possible applications in intelligent transportation systems, automation systems, and language processing. Vector Symbolic Architectures is an approach for encoding and manipulating distributed representations of information. They have previously been used mainly in the area of cognitive computing for representing and reasoning upon semantically bound information. First, it is shown that Vector Symbolic Architectures are capable of pattern classification of temporal patterns. With this approach, it is possible to represent, learn and subsequently classify vehicles using measurements from vibration sensors. Next, an architecture called Holographic Graph Neuron for one-shot learning of patterns of generic sensor stimuli is proposed. The architecture is based on implementing the Hierarchical Graph Neuron approach using Vector Symbolic Architectures. Holographic Graph Neuron shows the previously reported performance characteristics of Hierarchical Graph Neuron while maintaining the simplicity of its design. The Holographic Graph Neuron architecture is applied in two domains: fault detection and longest common substrings search. In the area of fault detection the architecture showed superior performance compared to classical methods of artificial intelligence while featuring zero configuration and simple operations. The application of the architecture for longest common substrings search showed its ability to robustly solve the task given that the length of a common substring is longer than 4{\%} of the longest pattern. Furthermore, the required number of operations on binary vectors is equal to the suffix trees approach, which is the fastest traditional algorithm for this problem. In summary, the work presented in this thesis extends understanding of the performance proprieties of distributed representations and opens the way for new applications.},
author = {Kleyko, Denis},
file = {:home/ksiks/temp/FULLTEXT01.pdf:pdf},
isbn = {978-91-7583-536-5},
title = {{Pattern Recognition with Vector Symbolic Architectures}},
year = {2016}
}
